# LLMs collection. Promts collection. AI-IDEs collection. Papers collection


## üõ†Ô∏è LLMs
|Logo|Vendor  | Description |
|----|--------|-------------|
| <img src="assets/openai.png" width="30">|[OpenAI](https://chatgpt.com) | GPT-5 is an iPhone in LLM space |
|<img src="assets/antropic.png" width="30">| [Anthropic](https://claude.ai) | Claude Sonnet 4 and Claude Opus 4.1 |
|<img src="assets/gemine.png" width="30">|[Google](https://gemini.google.com) | Gemini 2.5 PRO |
|<img src="assets/mistral.png" width="30">| [Mistral](https://chat.mistral.ai/chat) | Mistral AI. French company|
|<img src="assets/deepseek.png" width="30">|[DeepSeek](https://chat.deepseek.com/) | DeepSeek & DeepSeek R1 |
|<img src="assets/grok4.png" width="30">|[xAI](https://grok.com) | Grok 4 |
|<img src="assets/qwen3.jpeg" width="30">|[DeepSeek](https://chat.qwen.ai/) | Qwen3 |

## üõ†Ô∏è LLMs Aggregators
|Logo|Vendor  | Description |
|----|--------|-------------|
|<img src="assets/perplexity.png" width="30">|[Perplexity](https://www.perplexity.ai/) | main Perplexity AI platform, a smart chat-based search engine that combines AI (like Claude, GPT-5, Gemini) and real-time internet data|
|<img src="assets/perplexity.png" width="30">|[Perplexity Playground](https://playground.perplexity.ai/) | r1-1776, sonar-resoning-pro & other models |
|<img src="assets/llmarena.png" width="30">|[LmArena](https://lmarena.ai/) | Pretty nice collections of LLM models |





## üåÄ AI-IDEs
|Logo|Vendor  | Description |
|----|--------|-------------|
| <img src="assets/cursor.png" width="30">|[Cursor](https://www.cursor.com) | AI-first code editor built for pair-programming with models |
| <img src="assets/windsurf.png" width="30">|[Windsurf](https://windsurf.ai) | AI-powered IDE with advanced code completion and workflow automation |
| <img src="assets/zed.jpg" width="30">|[Zed](https://zed.dev) | High-performance, collaborative code editor with AI features |
| <img src="assets/fleet.png" width="30">| [JetBrains Fleet](https://www.jetbrains.com/fleet/) | Next-gen IDE with AI Assistant (JetBrains) |



## üî¨ Papers
|Year| Title  | Impact |
|----|--------|-------------|
| 2013 |[Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781) | Word2Vec |
| 2017 |[Attention Is All You Need](https://arxiv.org/abs/1706.03762) | Introducting Transformers  |
| 2018 |[Improving Language Understanding by Generative Pre-Training ](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf ) | GPT-1  |
| 2019 |[Language Models are Unsupervised Multitask Learners ]( https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) | GPT-2  |
| 2020 |[Language Models are Few-Shot Learners ]( https://arxiv.org/abs/2005.14165 ) |  GPT-3  |
| 2020 |[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks ](https://arxiv.org/abs/2005.11401 ) | -  |
|2022|[Research: quantifying GitHub Copilot‚Äôs impact on developer productivity and happiness ](https://github.blog/news-insights/research/research-quantifying-github-copilots-impact-on-developer-productivity-and-happiness/) |  Is this GitHub copilot helping developers?   |
| 2022 |[Training language models to follow instructions with human feedback ]( https://arxiv.org/abs/2203.02155) | Introducing RLHF. GPT-3.5, engine of ChatGPT  |
| 2022 |[ Constitutional AI: Harmlessness from AI Feedback](https://scalingintelligence.stanford.edu/pubs/constitutionalai.pdf ) | -  |
| 2022 |[Emergent Abilities of Large Language Models](https://arxiv.org/abs/2206.07682 ) | -  |
| 2022 |[Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters ]( https://arxiv.org/abs/2212.10001) |  - |
| 2023 |[Sparks of Artificial General Intelligence: Early experiments with GPT-4 ](https://arxiv.org/abs/2303.12712 ) |  - |
| 2023 |[GPT-4 Technical Report](https://arxiv.org/abs/2303.08774 ) | -  |
| 2023 |[Gemini: A Family of Highly Capable Multimodal Models ](https://arxiv.org/abs/2312.11805 ) | -  |
| 2023 |[ Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601 ) |  - |
| 2023 |[Large Language Models as Optimizers ](https://arxiv.org/abs/2309.03409 ) | -  |
| 2025 |[The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity](https://arxiv.org/abs/2506.06941) | -  |





 


